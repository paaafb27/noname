"""
ì „ì²´ ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í¼ í†µí•© í…ŒìŠ¤íŠ¸
"""
import sys
import os
import json
from datetime import datetime



# âœ… PYTHONPATHì— functions ë””ë ‰í† ë¦¬ ì¶”ê°€ (common ëª¨ë“ˆ ì¸ì‹ìš©)
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)  # scandeals-crawler
sys.path.insert(0, project_root)  # common ì ‘ê·¼ ê°€ëŠ¥
sys.path.insert(0, current_dir)    # functions ì ‘ê·¼ ê°€ëŠ¥

from fmkorea.scraper import FmkoreaScraper
from ppomppu.scraper import PpomppuScraper
from ruliweb.scraper import RuliwebScraper
from eomisae.scraper import EomisaeScraper
from arcalive.scraper import ArcaliveScraper
from quasarzone.scraper import QuasarzoneScraper

def test_scraper(scraper_class, site_name):
    """
    ê°œë³„ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜

    Args:
        scraper_class: ìŠ¤í¬ë˜í¼ í´ë˜ìŠ¤
        site_name: ì‚¬ì´íŠ¸ëª…

    Returns:
        dict: í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ì„±ê³µ/ì‹¤íŒ¨, ìˆ˜ì§‘ ê°œìˆ˜, ì†Œìš” ì‹œê°„)
    """
    print(f"\n{'='*50}")
    print(f"ğŸ“Œ {site_name} í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"{'='*50}\n")

    try:
        # ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
        scraper = scraper_class()

        if hasattr(scraper, 'test_mode'):
            scraper.test_mode = True

        start_time = datetime.now()
        results = scraper.scrape()
        end_time = datetime.now()

        # ê²°ê³¼ ì¶œë ¥
        duration = (end_time - start_time).total_seconds()
        print(f"\nâœ… {site_name} ì™„ë£Œ")
        print(f"   - ìˆ˜ì§‘ ê°œìˆ˜: {len(results)}ê°œ")
        print(f"   - ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ")

        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        if results:
            print(f"\n   [ì²« ë²ˆì§¸ í•­ëª© ìƒ˜í”Œ]")
            sample = results[0]
            print(f"   ì œëª©: {sample.get('title', 'N/A')[:50]}...")
            print(f"   ê°€ê²©: {sample.get('price', 'N/A')}")
            print(f"   íŒë§¤ì²˜: {sample.get('storeName', 'N/A')}")
            print(f"   ì‹œê°„: {sample.get('crawledAt', 'N/A')}")

            # ë°ì´í„° êµ¬ì¡° ê²€ì¦
            required_fields = ['title', 'productUrl', 'sourceSite', 'crawledAt']
            missing_fields = [f for f in required_fields if f not in sample]
            if missing_fields:
                print(f"   âš ï¸ ëˆ„ë½ëœ í•„ë“œ: {missing_fields}")
        else:
            print(f"   âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")

        return {
            'site': site_name,
            'success': True,
            'count': len(results),
            'duration': duration,
            'sample': results[0] if results else None
        }

    except Exception as e:
        print(f"\nâŒ {site_name} ì‹¤íŒ¨")
        print(f"   ì—ëŸ¬: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'site': site_name,
            'success': False,
            'error': str(e)
        }


def main():
    """ì „ì²´ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*50)
    print("ğŸš€ ì „ì²´ ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸")
    print("="*50)

    # í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ëª©ë¡
    scrapers = [
        (ArcaliveScraper, 'ARCALIVE'),
        (RuliwebScraper, 'RULIWEB'),
        (PpomppuScraper, 'PPOMPPU'),
        (EomisaeScraper, 'EOMISAE'),
        (FmkoreaScraper, 'FMKOREA'),
        (QuasarzoneScraper, 'QUASARZONE')
    ]

    # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_start = datetime.now()
    results = []

    for scraper_class, site_name in scrapers:
        result = test_scraper(scraper_class, site_name)
        results.append(result)

    test_end = datetime.now()
    total_duration = (test_end - test_start).total_seconds()

    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*50}\n")

    success_count = sum(1 for r in results if r['success'])
    total_items = sum(r.get('count', 0) for r in results if r['success'])

    print(f"âœ… ì„±ê³µ: {success_count}/{len(scrapers)}ê°œ")
    print(f"ğŸ“¦ ì´ ìˆ˜ì§‘: {total_items}ê°œ")
    print(f"â±ï¸ ì „ì²´ ì†Œìš” ì‹œê°„: {total_duration:.2f}ì´ˆ")
    print()

    # ìƒì„¸ ê²°ê³¼
    for result in results:
        status = "âœ…" if result['success'] else "âŒ"
        site = result['site']
        if result['success']:
            count = result['count']
            duration = result['duration']
            print(f"{status} {site:12s} - {count:3d}ê°œ ({duration:.1f}ì´ˆ)")
        else:
            error = result.get('error', 'Unknown error')
            print(f"{status} {site:12s} - ì‹¤íŒ¨: {error[:50]}...")

    # ê²°ê³¼ JSON ì €ì¥
    output_file = f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {output_file}")


if __name__ == '__main__':
    main()